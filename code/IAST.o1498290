===============================
1498290.pbshpc
vsky012.hpc.iitd.ac.in
===============================
/home/cse/phd/anz208849/IAST/code
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ImportError('/home/cse/phd/anz208849/anaconda3/envs/IAST/lib/python3.7/site-packages/amp_C.cpython-37m-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda12device_countEv')
DATASET:
  ANNS: ../data/cityscapes_train2.json
  IMAGEDIR: ../../scratch/data/cityscapes
  NUM_WORKER: 2
  RESIZE_SIZE: []
  TARGET:
    ANNS: ../data/darkzurich_train.json
    IMAGEDIR: ../../scratch/data/dark_zurich
    ORIGIN_SIZE: [1920, 1080]
    PSEUDO_BATCH_SIZE: 2
    PSEUDO_LOSS_WEIGHT: 1.0
    PSEUDO_PL: IAST
    PSEUDO_PL_ALPHA: 0.2
    PSEUDO_PL_BETA: 0.9
    PSEUDO_PL_GAMMA: 1.0
    PSEUDO_SAVE_DIR: 
    PSEUDO_SIZE: [1280, 640]
    SKIP_GEN_PSEUDO: False
    SOURCE_LOSS_WEIGHT: 1.0
    TYPE: MsDarkzurichDataset
  TYPE: MsCityscapesDataset
  USE_AUG: True
  VAL:
    ANNS: ../data/darkzurich_val.json
    IMAGEDIR: ../../scratch/data/dark_zurich_val
    ORIGIN_SIZE: [1920, 1080]
    RESIZE_SIZE: [1920, 1080]
    TYPE: DarkzurichDataset
MODEL:
  BACKBONE:
    PRETRAINED: True
    TYPE: R-DL-101-C1-C5-FREEZEBN
    WITH_IBN: False
  DECODER:
    TYPE: DeepLabV2Dedoder
  DISCRIMINATOR:
    LAMBDA_ENTROPY_WEIGHT: 0.0
    LAMBDA_KLDREG_WEIGHT: 0.0
    LOSS: MSELoss
    LR: [2e-05]
    TYPE: ['Origin-Predictor']
    UPDATE_T: 1.0
    WEIGHT: [0.05]
  PREDICTOR:
    LOSS: CrossEntropy
    NUM_CLASSES: 19
    TYPE: UpsamplePredictor
  TYPE: UDA_Segmentor
RANDOM_SEED: 888
TEST:
  BATCH_SIZE: 1
  NUM_WORKER: 2
  N_PROC_PER_NODE: 1
  RESIZE_SIZE: [[1280, 640]]
  USE_FLIP: False
TRAIN:
  APEX_OPT: O1
  BATCHSIZE: 6
  COSINEANNEALINGLR:
    T_MAX: 4
    T_MULT: 1.0
  EARLY_STOPPING: -1
  EPOCHES: 10
  ITER_REPORT: 100
  ITER_VAL: 400
  LR: 2e-05
  N_PROC_PER_NODE: 1
  OPTIMIZER: Adam
  PSEUDO_RESUME_FROM: 
  RESUME_FROM: ../../saved_models/IAST/source_only/best_iter.pth
  SAVE_ALL: False
  SCHEDULER: CosineAnnealingLR_with_Restart
WORK_DIR: ../../saved_models/IAST/warmup_at
resume from epoch 0 iter 0
Start training!
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
eta: 4h 03min, epoch: 1, iter: 100 , time: 3.008 s/iter, lr: 1.99e-05, D_lr: 1.99e-05, loss: 1.578195, D_Origin-Predictor_loss: 0.295057, mask_loss: 1.578195
eta: 3h 57min, epoch: 1, iter: 200 , time: 2.999 s/iter, lr: 1.95e-05, D_lr: 1.95e-05, loss: 0.861690, D_Origin-Predictor_loss: 0.223867, mask_loss: 0.861690
eta: 3h 52min, epoch: 1, iter: 300 , time: 2.997 s/iter, lr: 1.89e-05, D_lr: 1.89e-05, loss: 0.768759, D_Origin-Predictor_loss: 0.199808, mask_loss: 0.768759
eta: 3h 47min, epoch: 1, iter: 400 , time: 3.001 s/iter, lr: 1.81e-05, D_lr: 1.81e-05, loss: 0.664218, D_Origin-Predictor_loss: 0.195004, mask_loss: 0.664218
epoch: 1, val_miou: 0.0947(0.0947), 0: 0.3661, 1: 0.1078, 2: 0.4595, 3: 0.0073, 4: 0.0212, 5: 0.0830, 6: 0.0307, 7: 0.0167, 8: 0.3187, 9: 0.0444, 10: 0.0253, 11: 0.0605, 12: 0.0000, 13: 0.2537, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0044
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
eta: 3h 51min, epoch: 2, iter: 500 , time: 3.119 s/iter, lr: 1.70e-05, D_lr: 1.70e-05, loss: 0.614311, D_Origin-Predictor_loss: 0.193673, mask_loss: 0.614311
eta: 3h 37min, epoch: 2, iter: 600 , time: 3.004 s/iter, lr: 1.58e-05, D_lr: 1.58e-05, loss: 0.600165, D_Origin-Predictor_loss: 0.190663, mask_loss: 0.600165
eta: 3h 32min, epoch: 2, iter: 700 , time: 3.001 s/iter, lr: 1.44e-05, D_lr: 1.44e-05, loss: 0.543782, D_Origin-Predictor_loss: 0.188830, mask_loss: 0.543782
eta: 3h 27min, epoch: 2, iter: 800 , time: 3.000 s/iter, lr: 1.30e-05, D_lr: 1.30e-05, loss: 0.545323, D_Origin-Predictor_loss: 0.187368, mask_loss: 0.545323
epoch: 2, val_miou: 0.1129(0.1129), 0: 0.3904, 1: 0.1405, 2: 0.4837, 3: 0.0316, 4: 0.0705, 5: 0.1189, 6: 0.0787, 7: 0.0336, 8: 0.3449, 9: 0.0497, 10: 0.0193, 11: 0.0886, 12: 0.0000, 13: 0.2946, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0000
eta: 3h 26min, epoch: 2, iter: 900 , time: 3.053 s/iter, lr: 1.14e-05, D_lr: 1.14e-05, loss: 0.513777, D_Origin-Predictor_loss: 0.188261, mask_loss: 0.513777
eta: 3h 21min, epoch: 3, iter: 1000 , time: 3.067 s/iter, lr: 9.85e-06, D_lr: 9.85e-06, loss: 0.515368, D_Origin-Predictor_loss: 0.192940, mask_loss: 0.515368
eta: 3h 12min, epoch: 3, iter: 1100 , time: 3.001 s/iter, lr: 8.28e-06, D_lr: 8.28e-06, loss: 0.492262, D_Origin-Predictor_loss: 0.187664, mask_loss: 0.492262
eta: 3h 07min, epoch: 3, iter: 1200 , time: 3.001 s/iter, lr: 6.74e-06, D_lr: 6.74e-06, loss: 0.460030, D_Origin-Predictor_loss: 0.189909, mask_loss: 0.460030
epoch: 3, val_miou: 0.1236(0.1236), 0: 0.4462, 1: 0.1887, 2: 0.4981, 3: 0.0552, 4: 0.0983, 5: 0.1535, 6: 0.0830, 7: 0.0364, 8: 0.3551, 9: 0.0533, 10: 0.0140, 11: 0.0781, 12: 0.0000, 13: 0.2877, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0000
eta: 3h 06min, epoch: 3, iter: 1300 , time: 3.059 s/iter, lr: 5.29e-06, D_lr: 5.29e-06, loss: 0.485241, D_Origin-Predictor_loss: 0.192873, mask_loss: 0.485241
eta: 2h 57min, epoch: 3, iter: 1400 , time: 3.003 s/iter, lr: 3.96e-06, D_lr: 3.96e-06, loss: 0.448251, D_Origin-Predictor_loss: 0.190120, mask_loss: 0.448251
eta: 2h 58min, epoch: 4, iter: 1500 , time: 3.096 s/iter, lr: 2.78e-06, D_lr: 2.78e-06, loss: 0.450060, D_Origin-Predictor_loss: 0.190350, mask_loss: 0.450060
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
eta: 2h 47min, epoch: 4, iter: 1600 , time: 3.003 s/iter, lr: 1.78e-06, D_lr: 1.78e-06, loss: 0.470296, D_Origin-Predictor_loss: 0.186283, mask_loss: 0.470296
epoch: 4, val_miou: 0.1221(0.1236), 0: 0.4129, 1: 0.2163, 2: 0.4866, 3: 0.0495, 4: 0.0780, 5: 0.1420, 6: 0.0676, 7: 0.0373, 8: 0.3581, 9: 0.0455, 10: 0.0105, 11: 0.0831, 12: 0.0000, 13: 0.3326, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0001
eta: 2h 45min, epoch: 4, iter: 1700 , time: 3.061 s/iter, lr: 9.90e-07, D_lr: 9.90e-07, loss: 0.461805, D_Origin-Predictor_loss: 0.190209, mask_loss: 0.461805
eta: 2h 37min, epoch: 4, iter: 1800 , time: 3.000 s/iter, lr: 4.25e-07, D_lr: 4.25e-07, loss: 0.458270, D_Origin-Predictor_loss: 0.193129, mask_loss: 0.458270
eta: 2h 32min, epoch: 4, iter: 1900 , time: 3.002 s/iter, lr: 1.00e-07, D_lr: 1.00e-07, loss: 0.453410, D_Origin-Predictor_loss: 0.188362, mask_loss: 0.453410
eta: 2h 31min, epoch: 5, iter: 2000 , time: 3.075 s/iter, lr: 2.00e-05, D_lr: 2.00e-05, loss: 0.441550, D_Origin-Predictor_loss: 0.189007, mask_loss: 0.441550
epoch: 5, val_miou: 0.1218(0.1236), 0: 0.4095, 1: 0.2411, 2: 0.5069, 3: 0.0536, 4: 0.0583, 5: 0.1363, 6: 0.0677, 7: 0.0323, 8: 0.3592, 9: 0.0164, 10: 0.0062, 11: 0.0939, 12: 0.0000, 13: 0.3318, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0003
eta: 2h 25min, epoch: 5, iter: 2100 , time: 3.061 s/iter, lr: 1.98e-05, D_lr: 1.98e-05, loss: 0.465719, D_Origin-Predictor_loss: 0.196991, mask_loss: 0.465719
eta: 2h 17min, epoch: 5, iter: 2200 , time: 3.003 s/iter, lr: 1.94e-05, D_lr: 1.94e-05, loss: 0.425491, D_Origin-Predictor_loss: 0.199162, mask_loss: 0.425491
eta: 2h 12min, epoch: 5, iter: 2300 , time: 3.002 s/iter, lr: 1.87e-05, D_lr: 1.87e-05, loss: 0.431113, D_Origin-Predictor_loss: 0.197502, mask_loss: 0.431113
eta: 2h 07min, epoch: 5, iter: 2400 , time: 2.999 s/iter, lr: 1.79e-05, D_lr: 1.79e-05, loss: 0.414947, D_Origin-Predictor_loss: 0.197414, mask_loss: 0.414947
epoch: 5, val_miou: 0.1321(0.1321), 0: 0.3986, 1: 0.2081, 2: 0.5487, 3: 0.0815, 4: 0.1139, 5: 0.1603, 6: 0.0624, 7: 0.0394, 8: 0.3528, 9: 0.0155, 10: 0.0013, 11: 0.1263, 12: 0.0000, 13: 0.4006, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0007, 18: 0.0000
eta: 2h 08min, epoch: 6, iter: 2500 , time: 3.150 s/iter, lr: 1.68e-05, D_lr: 1.68e-05, loss: 0.409324, D_Origin-Predictor_loss: 0.197971, mask_loss: 0.409324
eta: 1h 57min, epoch: 6, iter: 2600 , time: 3.000 s/iter, lr: 1.55e-05, D_lr: 1.55e-05, loss: 0.390739, D_Origin-Predictor_loss: 0.201397, mask_loss: 0.390739
eta: 1h 52min, epoch: 6, iter: 2700 , time: 3.000 s/iter, lr: 1.42e-05, D_lr: 1.42e-05, loss: 0.392254, D_Origin-Predictor_loss: 0.199418, mask_loss: 0.392254
eta: 1h 47min, epoch: 6, iter: 2800 , time: 2.999 s/iter, lr: 1.27e-05, D_lr: 1.27e-05, loss: 0.376729, D_Origin-Predictor_loss: 0.197877, mask_loss: 0.376729
epoch: 6, val_miou: 0.1375(0.1375), 0: 0.3734, 1: 0.2625, 2: 0.5415, 3: 0.0712, 4: 0.0966, 5: 0.1752, 6: 0.0821, 7: 0.0417, 8: 0.3461, 9: 0.0668, 10: 0.0018, 11: 0.1150, 12: 0.0000, 13: 0.4380, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0001
eta: 1h 45min, epoch: 6, iter: 2900 , time: 3.075 s/iter, lr: 1.11e-05, D_lr: 1.11e-05, loss: 0.377713, D_Origin-Predictor_loss: 0.199180, mask_loss: 0.377713
eta: 1h 39min, epoch: 7, iter: 3000 , time: 3.065 s/iter, lr: 9.53e-06, D_lr: 9.53e-06, loss: 0.366947, D_Origin-Predictor_loss: 0.204045, mask_loss: 0.366947
eta: 1h 32min, epoch: 7, iter: 3100 , time: 3.002 s/iter, lr: 7.96e-06, D_lr: 7.96e-06, loss: 0.360419, D_Origin-Predictor_loss: 0.198993, mask_loss: 0.360419
eta: 1h 27min, epoch: 7, iter: 3200 , time: 3.003 s/iter, lr: 6.44e-06, D_lr: 6.44e-06, loss: 0.355579, D_Origin-Predictor_loss: 0.202012, mask_loss: 0.355579
epoch: 7, val_miou: 0.1402(0.1402), 0: 0.4041, 1: 0.2447, 2: 0.5527, 3: 0.0818, 4: 0.0899, 5: 0.1716, 6: 0.1166, 7: 0.0459, 8: 0.3645, 9: 0.0878, 10: 0.0015, 11: 0.1334, 12: 0.0008, 13: 0.3645, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0028, 18: 0.0007
eta: 1h 24min, epoch: 7, iter: 3300 , time: 3.060 s/iter, lr: 5.02e-06, D_lr: 5.02e-06, loss: 0.361476, D_Origin-Predictor_loss: 0.197533, mask_loss: 0.361476
eta: 1h 17min, epoch: 7, iter: 3400 , time: 2.999 s/iter, lr: 3.71e-06, D_lr: 3.71e-06, loss: 0.346765, D_Origin-Predictor_loss: 0.200512, mask_loss: 0.346765
eta: 1h 14min, epoch: 8, iter: 3500 , time: 3.073 s/iter, lr: 2.56e-06, D_lr: 2.56e-06, loss: 0.342745, D_Origin-Predictor_loss: 0.204973, mask_loss: 0.342745
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
eta: 1h 07min, epoch: 8, iter: 3600 , time: 3.002 s/iter, lr: 1.61e-06, D_lr: 1.61e-06, loss: 0.347396, D_Origin-Predictor_loss: 0.201147, mask_loss: 0.347396
epoch: 8, val_miou: 0.1460(0.1460), 0: 0.4069, 1: 0.3063, 2: 0.5572, 3: 0.0862, 4: 0.1048, 5: 0.1832, 6: 0.1112, 7: 0.0516, 8: 0.3617, 9: 0.0693, 10: 0.0012, 11: 0.1333, 12: 0.0000, 13: 0.3977, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0020, 18: 0.0006
eta: 1h 03min, epoch: 8, iter: 3700 , time: 3.063 s/iter, lr: 8.58e-07, D_lr: 8.58e-07, loss: 0.350539, D_Origin-Predictor_loss: 0.199253, mask_loss: 0.350539
eta: 0h 57min, epoch: 8, iter: 3800 , time: 2.998 s/iter, lr: 3.40e-07, D_lr: 3.40e-07, loss: 0.343742, D_Origin-Predictor_loss: 0.201078, mask_loss: 0.343742
eta: 0h 52min, epoch: 8, iter: 3900 , time: 3.002 s/iter, lr: 6.52e-08, D_lr: 6.52e-08, loss: 0.340111, D_Origin-Predictor_loss: 0.200898, mask_loss: 0.340111
eta: 0h 48min, epoch: 9, iter: 4000 , time: 3.071 s/iter, lr: 2.00e-05, D_lr: 2.00e-05, loss: 0.342641, D_Origin-Predictor_loss: 0.201337, mask_loss: 0.342641
epoch: 9, val_miou: 0.1498(0.1498), 0: 0.4416, 1: 0.3017, 2: 0.5547, 3: 0.0473, 4: 0.1309, 5: 0.1939, 6: 0.0927, 7: 0.0563, 8: 0.3640, 9: 0.0892, 10: 0.0042, 11: 0.1410, 12: 0.0000, 13: 0.4276, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0000, 18: 0.0006
eta: 0h 43min, epoch: 9, iter: 4100 , time: 3.060 s/iter, lr: 1.98e-05, D_lr: 1.98e-05, loss: 0.330753, D_Origin-Predictor_loss: 0.204844, mask_loss: 0.330753
eta: 0h 37min, epoch: 9, iter: 4200 , time: 3.001 s/iter, lr: 1.93e-05, D_lr: 1.93e-05, loss: 0.339674, D_Origin-Predictor_loss: 0.209230, mask_loss: 0.339674
eta: 0h 32min, epoch: 9, iter: 4300 , time: 3.003 s/iter, lr: 1.86e-05, D_lr: 1.86e-05, loss: 0.343537, D_Origin-Predictor_loss: 0.207733, mask_loss: 0.343537
eta: 0h 27min, epoch: 9, iter: 4400 , time: 3.003 s/iter, lr: 1.77e-05, D_lr: 1.77e-05, loss: 0.335218, D_Origin-Predictor_loss: 0.210534, mask_loss: 0.335218
epoch: 9, val_miou: 0.1583(0.1583), 0: 0.4556, 1: 0.2935, 2: 0.5706, 3: 0.0991, 4: 0.1528, 5: 0.1831, 6: 0.1208, 7: 0.0629, 8: 0.3703, 9: 0.0906, 10: 0.0035, 11: 0.1353, 12: 0.0000, 13: 0.4526, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0155, 18: 0.0014
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
eta: 0h 23min, epoch: 10, iter: 4500 , time: 3.111 s/iter, lr: 1.66e-05, D_lr: 1.66e-05, loss: 0.317757, D_Origin-Predictor_loss: 0.208275, mask_loss: 0.317757
eta: 0h 17min, epoch: 10, iter: 4600 , time: 3.001 s/iter, lr: 1.53e-05, D_lr: 1.53e-05, loss: 0.331795, D_Origin-Predictor_loss: 0.213402, mask_loss: 0.331795
eta: 0h 12min, epoch: 10, iter: 4700 , time: 3.002 s/iter, lr: 1.39e-05, D_lr: 1.39e-05, loss: 0.322047, D_Origin-Predictor_loss: 0.210360, mask_loss: 0.322047
eta: 0h 07min, epoch: 10, iter: 4800 , time: 3.002 s/iter, lr: 1.24e-05, D_lr: 1.24e-05, loss: 0.317308, D_Origin-Predictor_loss: 0.210093, mask_loss: 0.317308
epoch: 10, val_miou: 0.1528(0.1583), 0: 0.4417, 1: 0.3282, 2: 0.5516, 3: 0.0643, 4: 0.1011, 5: 0.1875, 6: 0.0874, 7: 0.0588, 8: 0.3570, 9: 0.1028, 10: 0.0005, 11: 0.1298, 12: 0.0000, 13: 0.4321, 14: 0.0000, 15: 0.0000, 16: 0.0000, 17: 0.0520, 18: 0.0082
eta: 0h 02min, epoch: 10, iter: 4900 , time: 3.063 s/iter, lr: 1.08e-05, D_lr: 1.08e-05, loss: 0.303515, D_Origin-Predictor_loss: 0.212837, mask_loss: 0.303515
End! epoch0 max metrics: 0.1583
